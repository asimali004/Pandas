{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1: EPIDEMIC MODELS AND DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is divided in two parts.\n",
    "\n",
    "\n",
    "PART 1:\n",
    "\n",
    "\n",
    "In this part you will build upon the SIR model that we saw in Lab1 and extend it to include the class for the Exposed population. You will define the system of ODEs, plotting functions, and solve the problem given some parameters. You will learn how to use the scipy library to solve differential equations and do some baseline scientific computing! The task here is to see how by using python we can model a disease's spread in a city or population, do data analysis and visualize our results.  The advanced task of this part introduces a lockdown policy in the population.\n",
    "\n",
    "\n",
    "PART 2:\n",
    "\n",
    "In this part, given a dataset, you will go through one of the most important steps in the data mining process. Data pre-processing! You will explore the dataset, plot the variables, handle the missing values, standardize the dataset and perform dimensionality reduction. The learning outcome of this part is to know how one can pre-process a real-world dataset and prepare for a supervised or an unsupervised learning task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Grading: \n",
    "\n",
    "1. Basic tasks: points  2\n",
    "2. Advanced tasks: points 2\n",
    "3. Total points: 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student information\n",
    "Please provide your information for automatic grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUD_SUID = 'mabu1800'\n",
    "STUD_NAME = 'mathias burestam'\n",
    "STUD_EMAIL = 'mathias.burestam@stud.dsv.su.se'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTLINE: \n",
    "\n",
    "PART 1:\n",
    "\n",
    "1. Basic Task: SEIR, total points: 1\n",
    "\n",
    "\n",
    "    a. sytem of ODES, points 0.3 \n",
    "    b. Parameter definition and problem solving, points 0.4 \n",
    "    c. plot function, points 0.3\n",
    "2. Advanced Task: SEIR with lockdown policy, total points: 1\n",
    "\n",
    "PART 2: Data pre-processing, plotting and dimensionality reduction\n",
    "\n",
    "(Basic Tasks: 1-5)\n",
    "\n",
    "(Advanced Task: 6)\n",
    "\n",
    "1. Reading the file, points: 0.1\n",
    "2. Missing Values, points: 0.3\n",
    "3. Plotting, total points: 0.2\n",
    "\n",
    "\n",
    "    a. plot_a, points: 0.05\n",
    "    b. plot_b, points: 0.05\n",
    "    c. plot_c, points: 0.05\n",
    "    d. plot_d, points: 0.05\n",
    "\n",
    "4. Standardization, points: 0.2\n",
    "5. Dimensionality reduction, total points: 0.2\n",
    "\n",
    "\n",
    "    a. pca plotting, points: 0.15\n",
    "    b. pca heatmap, points: 0.05\n",
    "\n",
    "6. Advanced task: Multi-Dimensional Scaling(MDS) , total points: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Each function you make will be graded, so it is important to strictly follow input and output instructions stated in the skeleton code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the libraries that you will need throughout the assignment\n",
    "from scipy.integrate import odeint\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "from HW1_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: EPIDEMIC MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic task: SEIR \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This is a similart version to the SEIR model found in wiki, without the vital dynamics: https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SEIR_model. For this homework we removed the vital dynamics from the model (reference: https://www.idmod.org/docs/emod/hiv/model-seir.html#seir-without-vital-dynamics ) to make it simpler (no births, no deaths in the population) \n",
    "\n",
    "\n",
    "Many infectious diseases have an incubation period before being infectious during which the host cannot yet spread the disease.\n",
    "This delay between the acquisition of infection and the infectious state can be incorporated within the SIR model by adding a latent/exposed population, E, and letting infected (but not yet infectious) individuals move from S to E and from E to I.\n",
    "\n",
    "\n",
    "$\\frac{dS}{dt} = -\\beta*I*\\frac{S}{N}$\n",
    "\n",
    "$\\frac{dE}{dt} = \\beta*I*\\frac{S}{N} - \\delta*E$\n",
    "\n",
    "$\\frac{dI}{dt} = \\delta*E - \\gamma*I$\n",
    "\n",
    "$\\frac{dR}{dt} = \\gamma*I$\n",
    "\n",
    "\n",
    "The infectious rate, $\\beta$, controls the rate of spread which represents the probability of transmitting a disease between a susceptible and an infectious individual. The incubation rate, $\\delta$, is the rate of latent individuals becoming infectious (average duration of incubation is $\\frac{1}{\\delta}$). Recovery rate, $\\gamma$ = 1/D, is determined by the average duration, D, of infection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. System of ODEs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function named deriv_seir:\n",
    "- implement the above system of ODEs for SEIR, in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_seir(y, t, N, beta, gamma, delta):\n",
    "    \"\"\"\n",
    "    Input: y, time grid, N: total population, beta: infectious rate, gamma: recovery rate, delta: incubation period \n",
    "    Output: dSdt, dEdt, dIdt, dRdt\n",
    "    Transform the above system of ODEs in python\n",
    "    \"\"\"\n",
    "    S, E, I, R = y\n",
    "    \n",
    "    #Write your code here\n",
    "    \n",
    "      # Change in S population over time\n",
    "    dSdt = -beta * S * I / N\n",
    "    # Change in E population over time\n",
    "    dEdt = beta * S * I / N - delta * E\n",
    "    # Change in I population over time\n",
    "    dIdt = beta * S * I / N - gamma * I\n",
    "    # Change in R population over time\n",
    "    dRdt = gamma * I\n",
    "\n",
    "    return dSdt, dEdt, dIdt, dRdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Parameter definition and solving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function named model_seir, given the model parameters, define:\n",
    "- the initial conditions (one exposed, rest susceptible), \n",
    "- the grid of time-points in days (150 days), \n",
    "- the initial conditions vector and \n",
    "- finally solve the system of ODEs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_seir(N, beta, gamma, delta):\n",
    "    \"\"\"\n",
    "    Input: N:total population, beta: infectious rate, gamma: recovery rate, delta: incubation period \n",
    "    Output: time, S, E, I, R\n",
    "\n",
    "    step1: define the initial conditions: one exposed, rest susceptible\n",
    "    step2: define the grid of time points in days (use 150 days)\n",
    "    step3: define the initital conditions vector y0\n",
    "    step3: solve the system of ODEs using odeint from scipy\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return t, S, E, I, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the model parameters, do not change them.\n",
    "N = 1000\n",
    "beta = 1.0\n",
    "D = 10\n",
    "gamma = 1.0/D\n",
    "delta = 1.0/5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the model_seir function that you defined above and storing the results in t, S, E, I, R\n",
    "t, S, E, I, R = model_seir(N, beta, gamma, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you complete the method, you can run the following line to check whether your functions are correct or not. \n",
    "check_model_seir(t,S,E,I,R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Plot function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function called plot_seir(): \n",
    "- plot the S, E, I, R compartments. \n",
    "- include a dashed line for the total number of the population (S+E+I+R).\n",
    "- include labels that depict which line is for which population (using legend)\n",
    "\n",
    "\n",
    "Specifically the plot should contain: \n",
    "\n",
    "- On the x-axis: the population\n",
    "\n",
    "- On the y-axis: Time in days\n",
    " \n",
    "\n",
    "In the function below you will notice that in the list of parameters is included (...., L=None). The purpose of this parameter is to add a title regarding the lockdown day that you will see in the advanced task. For this part it will not print anything. Do not remove it or change it, even if it does not do anything, as you will need it for the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seir(t,S,E,I,R,L=None):\n",
    "    \"\"\"\n",
    "    Input: t, S, E, I, R, L (the L parameter is for the next question that introduces a lockdown, for this part it will not do anything so do not change L=None)\n",
    "     \n",
    "\n",
    "    step1: create the figure and subplots with nrows=1 and and ncols=1.\n",
    "    step2: plot the susceptible, exposed, infected, recovered, and total population\n",
    "    step3: set x and y label and tick parameters\n",
    "    step4: add the corresponding names of each line using legend\n",
    "     \n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if L is not None:\n",
    "        plt.title(\"Lockdown after {} days\".format(L))\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling plot_seir here\n",
    "plot_seir(t,S,E,I,R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Task: Lockdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you will build upon the previous model and you will introduce a Lockdown policy.\n",
    "Until now, the model you defined was highly unrealistic as the R0-value was constant. If a government introduces a lockdown in the country then the basic reproductive number(R0) drops! Meaning that you have to adapt the parameters to change over time.  \n",
    "\n",
    "Your task is as follows:\n",
    "\n",
    "- Re-write the system of ODEs for SEIR in the function called deriv_seir_lockdown. The reason why you should define the function again, is that, this time, the $\\beta$ is time dependent. Other than that, the system of ODEs remains the same. \n",
    "\n",
    "- Next, in the function, named model_seir_lockdown(), define:\n",
    "\n",
    "    -the time dependent $R_0$ and $\\beta$ as mentioned in 1, 2 just below the bullet points.\n",
    "\n",
    "    -the initial conditions (one exposed, rest susceptible), \n",
    "\n",
    "    -the grid of time-points in days (150 days), \n",
    "\n",
    "    -the initial conditions vector and \n",
    "    \n",
    "    -finally solve the system of ODEs. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. Time dependent $R_0$:\n",
    "\n",
    "\n",
    "Say that the lockdown is introduced on day 30 after the first case of the disease in the country. In that case the $R_0$ drops to 0.9 the day of the lockdown. The value of $R_0$ before that day was 5.7\n",
    "\n",
    "2. Time dependent $\\beta$:\n",
    "\n",
    "Remember that the definition of beta is $\\beta$ = $R_0$* $\\gamma$. If $R_0$ is time dependent then $\\beta$ is also time dependent.     \n",
    "\n",
    "\n",
    "To plot your model, the plot_seir() function that was defined in question .c is used again, but now in the list of parameters is also the lockdown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_seir_lockdown(y, t, N, beta, gamma, delta):\n",
    "    \"\"\"\n",
    "    Input: y, time grid, N: total population, beta: infectious rate, gamma: recovery rate, delta: incubation period \n",
    "    Output: dSdt, dEdt,  dIdt, dRdt\n",
    "  \n",
    "    Transform the above system of ODEs in python considering this time: time dependent beta\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    S, E, I, R = y\n",
    "    #implement the new SEIR equations here. The SEIR equations are the same as defined above \n",
    "    \n",
    "    ##but now beta is time dependent!: beta(t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return dSdt, dEdt, dIdt, dRdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_seir_lockdown(gamma, delta):\n",
    "    \"\"\"\n",
    "    Input: gamma, delta\n",
    "    Output: t,S,E,I,R,L\n",
    "\n",
    "\n",
    "    step1: define, in R_0(t), the time dependent R0\n",
    "    step2: define, in beta(t), the time dependent beta\n",
    "    step3: set initial conditions, one exposed, rest susceptible\n",
    "    step4: fill in the grid of time points (in days) (you should consider 150 days)\n",
    "    step5: fill in the initial conditions vector\n",
    "    step5: use odeint from scipy to solve the system ODEs\n",
    "\n",
    "    \"\"\"\n",
    "    L = 30 #day of lockdown\n",
    "\n",
    "\n",
    "    def R_0(t):\n",
    "        #R0 equals to 5.7 if the current day is before the lockdown day (L) and R0 equals to 0.9 if the current day is equal or after the lockdown day (L)\n",
    "\n",
    "        #write your code here for R_0(t)\n",
    "        return ...\n",
    "    \n",
    "    def beta(t):\n",
    "        #remember beta = R0*gamma\n",
    "\n",
    "        #write your code here for beta(t)\n",
    "        return ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #write your code here (after step3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return t, S, E, I, R, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000\n",
    "D = 10\n",
    "gamma = 1.0/D\n",
    "delta = 1.0/5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the model_seir_lockdown function that you defined above and storing the results in t, S, E, I, R, L\n",
    "t, S, E, I, R, L = model_seir_lockdown(gamma,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you complete the method, you can run the following line to check whether your functions are correct or not. \n",
    "check_model_seir_lockdown(t,S,E,I,R,L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling plot_seir() here\n",
    "plot_seir(t, S, E, I, R, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: DATA PRE-PROCESSING, PLOTTING AND DIMENSIONALITY REDUCTION\n",
    "\n",
    "## (Basic Tasks: 1-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *1.* Reading the file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the \"adult.data\" dataset which is under the folder  named \"datasets\". \n",
    "You can read information about the dataset here: http://archive.ics.uci.edu/ml/datasets/Adult\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "- income: >50K, <=50K\n",
    "\n",
    "- age: continuous.\n",
    "\n",
    "- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "\n",
    "- fnlwgt: continuous.\n",
    "\n",
    "- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, \n",
    "Doctorate, 5th-6th, Preschool.\n",
    "education-num: continuous.\n",
    "\n",
    "- education-num: continuous.\n",
    "\n",
    "- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "\n",
    "- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "\n",
    "- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "\n",
    "- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "\n",
    "- sex: Female, Male.\n",
    "\n",
    "- capital-gain: continuous.\n",
    "\n",
    "- capital-loss: continuous.\n",
    "\n",
    "- hours-per-week: continuous.\n",
    "\n",
    "- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"datasets/adult.data\", header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the function named basic_preprocessing, that takes as input the dataframe called data, do the following: \n",
    "\n",
    "- Change the column names to their corresponding ones, as seen above in attribute information\n",
    "\n",
    "- Rename the class label (income) to ' <=50K': 0, ' >50K': 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_preprocessing(data):\n",
    "    \"\"\"\n",
    "    Input: the dataset\n",
    "    Output: the dataset with the below changes, named data_renamed\n",
    "\n",
    "    step1: change the column names \n",
    "    step2: rename the class label\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return data_renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calling the function here:\n",
    "data = basic_preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if you want to see information about the dataset:\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to see information about the dataset:\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *2.* Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Note: Missing values in the file are represented as “ ?”. Note that there is a space before the ?.\n",
    "\n",
    "a. In the function named missing_values_and_plotting do the following:\n",
    "- Check how many missing values exist per attribute in the dataframe. Store the result in a pd.Series called missing_values_count. \n",
    "- Plot the missing_values_count as a barplot (you can use kind=”barh”). The names of the features should appear in the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_and_plotting(data):\n",
    "    \"\"\"\n",
    "    input: the adult dataset that you preprocessed in question 1\n",
    "    output: the series that has the counts of missing values per attribute, named missing_values_count\n",
    "\n",
    "    step1: store the number of missing values per attribure, in the series called missing_values_count\n",
    "    step2: plot the missing values series as a barplot. You can use pandas to plot the series. \n",
    "\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return missing_values_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calling the function\n",
    "missing_values_count = missing_values_and_plotting(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you complete the method, you can run the following line to check whether the output of the missing_values_count is correct or not. \n",
    "check_2a(missing_values_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. In the function named drop_missing_values, do the following:\n",
    "- Replace the missing values(\" ?\") with np.nan. \n",
    "- Drop the np.nan values.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(data):\n",
    "    \"\"\"\n",
    "    Input: the dataset\n",
    "    Outplut: the dataframe with the dropped values\n",
    "\n",
    "    step1: replace the ' ?' with np.nan\n",
    "    step2: drop the nan values and store the result in data_dropped\n",
    "    \n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return data_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the drop_missing_values() here\n",
    "data_dropped = drop_missing_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure that the rows that have missing values are deleted.\n",
    "data_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you complete the method, you can run the following line to check whether the number of the rows of data_dropped is correct or not.\n",
    "#in the number of rows pass the number of rows the data_dropped has. \n",
    "number_of_rows = None #change None to the number of rows data_dropped has. \n",
    "check_2b(number_of_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *3.* Plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\tIn the function named plot_a do the following:\n",
    "- Store in a pd.Series(), called unique_values_of_class, the count of unique values of the class label(how many people have income >50K and <=50K?).\n",
    "- Then plot a barplot of the class label. You can use pandas to plot. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_a(data):\n",
    "    \"\"\"\n",
    "    Input: the dataframe with the dropped values from question 2c.\n",
    "    Output: a pd.Series(), called unique_values_of_class, with the count of unique values for the class label (income).\n",
    "\n",
    "\n",
    "    step1: find the count of unique values for the class label. You can use value_counts().\n",
    "    step2: plot a barplot of the unique_values_of_class using pandas.\n",
    "    \"\"\"\n",
    "\n",
    "    #Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return unique_values_of_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calling plot_a()\n",
    "unique_values_of_class = plot_a(data_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_of_class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you complete the method, you can run the following line to check whether the output of the unique_values_of_class is correct or not. \n",
    "check_3a(unique_values_of_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.\tIn the function named plot_b do the following:\n",
    "- Store in a dataframe named sex_by_class, the respective counts of class labels by sex. (How many women/men have a class label of 0? How many women/men have a class label of 1?)\n",
    "- Examine the attribute sex by plotting a barplot in relation to the income. You can use pandas again. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_b(data):\n",
    "    \"\"\"\n",
    "    Input: the dataset with the dropped missing values.\n",
    "    Output: the dataframe that groups the input data by sex and counts the number of the two class labels per sex. \n",
    "\n",
    "\n",
    "    step1: store in a dataframe named sex_by_class, a dataframe with the respective counts of class labels by sex. \n",
    "    step2: Plot a barplot for the sex_by_class. You can use pandas to plot it.\n",
    "\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return sex_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function:\n",
    "sex_by_class = plot_b(data_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you complete the method, you can run the following lines to check whether the output values of the sex_by_class dataframe is correct or not. \n",
    "female_0 = None #change None to write here how many females have a class label of 0 (income<=50K).\n",
    "female_1 = None #change None to write here how many females have a class label of 1 (income>50K).\n",
    "male_0 = None #change None to write here how many males have a class label of 0 (income<=50K).\n",
    "male_1 = None #change None to write here how many males have a class label of 1 (income>50K).\n",
    "check_3b(female_0, female_1, male_0, male_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.\tIn the function named plot_c do the following:\n",
    "- Divide the age column into the following age groups: 0-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-100 using the cut function from pandas. The new column should be called age_bins.\n",
    "- Plot a bar chart for the attribute age_bins, in relation to the class label (income).\n",
    "- Return the dataframe that has all the original features plus the new one that you created called \"age_bins\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_c(data):\n",
    "    \"\"\"\n",
    "    input: the dataset with the dropped missing values\n",
    "    output: the new dataframe the has all the of data_dropped plus the \"age_bins\" column\n",
    "\n",
    "    step1: Create a new column in the input dataframe called \"age_bins\" and use pd.cut() to divide the age column into the above mentioned age groups. \n",
    "    step2: Store in a dataframe named age_by_class, a dataframe with the count of class labels by age_bins. \n",
    "    step3: Create a barplot for age_by_class\n",
    "\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function here:\n",
    "age_bins_df = plot_c(data_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.\tIn the function named plot_c do the following:\n",
    "- Create a sample of the dataset with only 1500 rows, using random_state=8 with *no replacement* and store it into a new dataframe called *data_sampled*.\n",
    "- Make a pairplot of all the numerical values of the sampled dataset and pass the following attributes into the pairplot function: diag_kind='hist' and hue='income'. Use seaborn!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_d(data):\n",
    "    \"\"\"\n",
    "    input: the dataset with the dropped missing values\n",
    "    output: the sampled dataset called data_sampled\n",
    "\n",
    "\n",
    "    step1: create a sample of the dataset with only 1500 rows, using random_state=8 with no replacement and store it into a new dataframe called data_sampled\n",
    "    step2: make a pairplot, using seaborn, of all the numerical values of the sampled dataset and pass the following attributes into the pairplot function: diag_kind='hist' and hue='income'\n",
    "\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return data_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function here:\n",
    "data_sampled = plot_d(data_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *4.* Standardization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function named standardize_it:\n",
    "\n",
    "- Standardize only the numerical features of the sampled dataframe. You can use the StandardScaler from sklearn.\n",
    "- Store in a variable called y the column of the class label of the sampled dataframe.\n",
    "- Transform the standardized numpy matrix returned by StandardScaler into a dataframe, with column names their corresponding names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_it(data):\n",
    "    \"\"\"\n",
    "    Input: the sampled_dataframe.\n",
    "    Output: the standardized dataframe called data_standardized and the class label of the sampled dataframe called y. \n",
    "\n",
    "    step1: extract only the numerical features from the sampled dataframe as well as the class label.\n",
    "    step2: use StandardScaler to fit_transform the dataframe with the numerical features.\n",
    "    step3: transform the standardized numpy matrix returned by StandardScaler into a dataframe.\n",
    "    step4: rename the columns of the dataframe with their corresponding names.\n",
    "\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return data_standardized, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling standardize_it() here\n",
    "data_standardized, y = standardize_it(data_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *5.* Dimensionality Reduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\tIn the function named pca_plotting do the following:\n",
    "- Perform PCA(with random_state=8) using 2 principal components on the standardized dataset. Use the sklearn library.\n",
    "- Store the explained variance ratio in an attribute called explained_variance_ratio.\n",
    "- Store in a dataframe called df_principal_components, a dataframe that has as rows the pca components and as columns the sampled dataframe's columns.\n",
    "- Plot the two principal components with colors respective to the class label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_plotting(data):\n",
    "    \"\"\"\n",
    "    Input: the standardized dataframe\n",
    "    Output: the principal components dataframe, the explained_variance_ratio\n",
    "\n",
    "    step1: perform pca with 2 principal components and random_state=8\n",
    "    step2: store the explained variance ratio in an attribute called explained_variance_ratio\n",
    "    step3: store in a dataframe called df_principal_components, a dataframe that has as rows the pca components and as columns names the sampled dataframe's columns\n",
    "    step4: plot the principal components using a scatterplot and colors respective to the class label\n",
    "\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return df_principal_components, explained_variance_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function here:\n",
    "df_principal_components, explained_variance_ratio = pca_plotting(data_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principal_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you complete the method, you can run the following line to check whether the output of df_principal_components and explained_variance_ratio are correct or not. \n",
    "check_5a(df_principal_components, explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. In the function called heatmap:\n",
    "- Use seaborn to plot the heatmap using the dataframe you returned in the previous question.\n",
    "\n",
    "In the attribure_contributing_the_most store the name of the attribure that contribures the most to the variance for the 2nd principal component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data):\n",
    "    \"\"\"\n",
    "    Input: df_principal_components\n",
    "\n",
    "    Use seaborn to plot the heatmap\n",
    "\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function here:\n",
    "heatmap(df_principal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribure_contributing_the_most = None #change None with the name of the attribute that contributes the most to the variance, use \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you complete the method, you can run the following line to check whether the attribure that you stored in attribure_contributing_the_most is the correct one. \n",
    "check_5b(attribure_contributing_the_most)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced task: Multi-Dimensional Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task:\n",
    "- perform  MDS on the data sampled with random state=8. Use sklearn.\n",
    "- Plot the results with colors respective to the class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "step1: fit the MDS with n_components=2, max_iter=100, random_State=8 and save it into the variable called X_2d\n",
    "step2: plot the results with colors respective to the class labels\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of HW 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
